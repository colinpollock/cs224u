{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch SST #\n",
    "I implemented different models in `torch_sst.py` and this notebook tests them against the Stanford Sentiment Treebank dataset.\n",
    "\n",
    "Models:\n",
    "* Bag of words with a dense output layer\n",
    "* Averaging the GloVe vectors for each token and passing the output to a dense layer\n",
    "* RNN (RNN, LSTM, GRU)\n",
    "\n",
    "There are a lot of improvements that'd lift all of these models' performance (e.g. balance the training set), but I just wanted to look at the relative performance. Overall the BOW model and the bidirectional LSTM/GRU perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch_sst import BOWClassifier, GloveClassifier, RnnClassifier, load_raw_data, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = load_raw_data('train')\n",
    "dev_texts, dev_labels = load_raw_data('dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with GloVe Vectors ##\n",
    "\n",
    "### Findings: ###\n",
    "* LSTM, GRU: improvement in macro F1 of 7% and 9% respectively.\n",
    "* Bidirectional: 12% improvement in macro F1\n",
    "* Not freezing embeddings: bidirectional LSTM and unfreezing gave the model way more power. It almost perfectly fit the train set (macro F1 of 96%) and performed a little worse on the dev set than the bidirectional LSTM with frozen embeddings. \n",
    "\n",
    "### TODO: ###\n",
    "* Keep going with the bidirectional LSTM with unfrozen embeddings. It fits the training set well, so try adding regularization.\n",
    "* Stacked (deep) RNNs\n",
    "* Search over learning rate / batch size, hidden dimension, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 70.11\t0.44\n",
      "Epoch 2: 68.95\t0.47\n",
      "Epoch 3: 68.59\t0.48\n",
      "Epoch 4: 68.36\t0.48\n",
      "Epoch 5: 68.22\t0.48\n",
      "Epoch 6: 68.09\t0.48\n",
      "Epoch 7: 68.00\t0.48\n",
      "Epoch 8: 68.09\t0.47\n",
      "Epoch 9: 67.88\t0.48\n",
      "Epoch 10: 67.80\t0.48\n",
      "Epoch 11: 67.79\t0.48\n",
      "Epoch 12: 67.65\t0.48\n",
      "Epoch 13: 67.56\t0.48\n",
      "Epoch 14: 67.65\t0.47\n",
      "Epoch 15: 67.58\t0.47\n",
      "Epoch 16: 67.63\t0.48\n",
      "Epoch 17: 67.47\t0.48\n",
      "Epoch 18: 67.42\t0.48\n",
      "Epoch 19: 67.39\t0.49\n",
      "Epoch 20: 67.35\t0.48\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.55      0.50      3310\n",
      "     neutral       0.48      0.02      0.03      1624\n",
      "    positive       0.50      0.64      0.56      3610\n",
      "\n",
      "    accuracy                           0.48      8544\n",
      "   macro avg       0.48      0.40      0.37      8544\n",
      "weighted avg       0.48      0.48      0.44      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.54      0.50       428\n",
      "     neutral       0.38      0.01      0.03       229\n",
      "    positive       0.48      0.63      0.54       444\n",
      "\n",
      "    accuracy                           0.47      1101\n",
      "   macro avg       0.44      0.39      0.35      1101\n",
      "weighted avg       0.45      0.47      0.42      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_classifier = RnnClassifier(hidden_dimension=50, rnn_type='rnn', num_classes=3, epochs=20, print_every=1, bidirectional=False)\n",
    "experiment(rnn_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 69.84\t0.44\n",
      "Epoch 2: 65.71\t0.53\n",
      "Epoch 3: 61.58\t0.59\n",
      "Epoch 4: 60.79\t0.60\n",
      "Epoch 5: 60.11\t0.60\n",
      "Epoch 6: 59.21\t0.61\n",
      "Epoch 7: 58.24\t0.62\n",
      "Epoch 8: 58.28\t0.62\n",
      "Epoch 9: 57.62\t0.63\n",
      "Epoch 10: 57.17\t0.63\n",
      "Epoch 11: 56.52\t0.63\n",
      "Epoch 12: 56.04\t0.64\n",
      "Epoch 13: 55.68\t0.64\n",
      "Epoch 14: 55.84\t0.64\n",
      "Epoch 15: 55.01\t0.64\n",
      "Epoch 16: 55.07\t0.65\n",
      "Epoch 17: 53.97\t0.66\n",
      "Epoch 18: 54.33\t0.65\n",
      "Epoch 19: 54.26\t0.65\n",
      "Epoch 20: 53.27\t0.66\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.67      0.69      3310\n",
      "     neutral       0.45      0.12      0.19      1624\n",
      "    positive       0.64      0.88      0.74      3610\n",
      "\n",
      "    accuracy                           0.65      8544\n",
      "   macro avg       0.60      0.56      0.54      8544\n",
      "weighted avg       0.63      0.65      0.62      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.62      0.63       428\n",
      "     neutral       0.30      0.07      0.11       229\n",
      "    positive       0.58      0.83      0.69       444\n",
      "\n",
      "    accuracy                           0.59      1101\n",
      "   macro avg       0.51      0.51      0.48      1101\n",
      "weighted avg       0.55      0.59      0.55      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_classifier = RnnClassifier(hidden_dimension=50, rnn_type='rnn', num_classes=3, epochs=20, print_every=1, bidirectional=True)\n",
    "experiment(rnn_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 69.22\t0.46\n",
      "Epoch 2: 62.93\t0.58\n",
      "Epoch 3: 59.37\t0.61\n",
      "Epoch 4: 57.29\t0.63\n",
      "Epoch 5: 55.69\t0.63\n",
      "Epoch 6: 54.25\t0.64\n",
      "Epoch 7: 53.26\t0.66\n",
      "Epoch 8: 52.25\t0.66\n",
      "Epoch 9: 50.89\t0.67\n",
      "Epoch 10: 50.11\t0.68\n",
      "Epoch 11: 49.41\t0.68\n",
      "Epoch 12: 48.08\t0.69\n",
      "Epoch 13: 47.25\t0.70\n",
      "Epoch 14: 46.20\t0.71\n",
      "Epoch 15: 45.43\t0.71\n",
      "Epoch 16: 44.32\t0.72\n",
      "Epoch 17: 43.31\t0.73\n",
      "Epoch 18: 41.91\t0.74\n",
      "Epoch 19: 40.92\t0.74\n",
      "Epoch 20: 39.82\t0.75\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79      3310\n",
      "     neutral       0.56      0.36      0.44      1624\n",
      "    positive       0.81      0.87      0.84      3610\n",
      "\n",
      "    accuracy                           0.76      8544\n",
      "   macro avg       0.71      0.69      0.69      8544\n",
      "weighted avg       0.74      0.76      0.74      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.71      0.68       428\n",
      "     neutral       0.29      0.16      0.21       229\n",
      "    positive       0.68      0.77      0.72       444\n",
      "\n",
      "    accuracy                           0.62      1101\n",
      "   macro avg       0.54      0.55      0.53      1101\n",
      "weighted avg       0.58      0.62      0.60      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_classifier = RnnClassifier(hidden_dimension=50, rnn_type='lstm', num_classes=3, epochs=20, print_every=1, bidirectional=True)\n",
    "experiment(rnn_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 68.79\t0.48\n",
      "Epoch 2: 62.32\t0.58\n",
      "Epoch 3: 58.03\t0.62\n",
      "Epoch 4: 56.56\t0.63\n",
      "Epoch 5: 54.81\t0.65\n",
      "Epoch 6: 53.69\t0.65\n",
      "Epoch 7: 52.57\t0.66\n",
      "Epoch 8: 51.91\t0.66\n",
      "Epoch 9: 50.53\t0.67\n",
      "Epoch 10: 49.75\t0.68\n",
      "Epoch 11: 48.55\t0.69\n",
      "Epoch 12: 47.48\t0.69\n",
      "Epoch 13: 46.14\t0.71\n",
      "Epoch 14: 45.16\t0.71\n",
      "Epoch 15: 43.86\t0.73\n",
      "Epoch 16: 41.95\t0.74\n",
      "Epoch 17: 40.91\t0.75\n",
      "Epoch 18: 39.56\t0.75\n",
      "Epoch 19: 38.30\t0.76\n",
      "Epoch 20: 37.00\t0.77\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.92      0.80      3310\n",
      "     neutral       0.56      0.32      0.41      1624\n",
      "    positive       0.88      0.80      0.84      3610\n",
      "\n",
      "    accuracy                           0.75      8544\n",
      "   macro avg       0.71      0.68      0.68      8544\n",
      "weighted avg       0.75      0.75      0.74      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70       428\n",
      "     neutral       0.30      0.15      0.20       229\n",
      "    positive       0.72      0.72      0.72       444\n",
      "\n",
      "    accuracy                           0.63      1101\n",
      "   macro avg       0.55      0.55      0.54      1101\n",
      "weighted avg       0.59      0.63      0.60      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_classifier = RnnClassifier(hidden_dimension=50, rnn_type='gru', num_classes=3, epochs=20, print_every=1, bidirectional=True)\n",
    "experiment(rnn_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 69.16\t0.47\n",
      "Epoch 2: 59.49\t0.61\n",
      "Epoch 3: 50.23\t0.69\n",
      "Epoch 4: 43.20\t0.73\n",
      "Epoch 5: 36.62\t0.77\n",
      "Epoch 6: 30.49\t0.82\n",
      "Epoch 7: 24.26\t0.86\n",
      "Epoch 8: 20.18\t0.89\n",
      "Epoch 9: 15.99\t0.92\n",
      "Epoch 10: 12.01\t0.95\n",
      "Epoch 11: 10.36\t0.96\n",
      "Epoch 12: 8.00\t0.97\n",
      "Epoch 13: 6.15\t0.98\n",
      "Epoch 14: 5.31\t0.98\n",
      "Epoch 15: 4.25\t0.98\n",
      "Epoch 16: 3.48\t0.99\n",
      "Epoch 17: 2.74\t0.99\n",
      "Epoch 18: 2.72\t0.99\n",
      "Epoch 19: 2.50\t0.99\n",
      "Epoch 20: 3.06\t0.99\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99      3310\n",
      "     neutral       0.91      0.97      0.94      1624\n",
      "    positive       1.00      0.96      0.98      3610\n",
      "\n",
      "    accuracy                           0.97      8544\n",
      "   macro avg       0.96      0.97      0.97      8544\n",
      "weighted avg       0.98      0.97      0.97      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.60      0.63       428\n",
      "     neutral       0.28      0.43      0.34       229\n",
      "    positive       0.71      0.56      0.63       444\n",
      "\n",
      "    accuracy                           0.55      1101\n",
      "   macro avg       0.55      0.53      0.53      1101\n",
      "weighted avg       0.60      0.55      0.57      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the best RNN type so far, LSTM, and unfreezing the embedding layer\n",
    "rnn_classifier = RnnClassifier(hidden_dimension=50, rnn_type='lstm', num_classes=3, epochs=20, print_every=1, bidirectional=True, update_glove=True)\n",
    "experiment(rnn_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Averaged Classifier ##\n",
    "\n",
    "Use pre-trained GloVe vectors. Average the vectors across all tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: 58.06\t0.62\n",
      "Epoch 200: 55.99\t0.64\n",
      "Epoch 300: 54.48\t0.65\n",
      "Epoch 400: 53.14\t0.66\n",
      "Epoch 500: 51.69\t0.67\n",
      "Epoch 600: 50.37\t0.68\n",
      "Epoch 700: 48.79\t0.69\n",
      "Epoch 800: 48.08\t0.69\n",
      "Epoch 900: 46.20\t0.71\n",
      "Epoch 1000: 45.21\t0.72\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.66      0.65      3310\n",
      "     neutral       0.32      0.16      0.21      1624\n",
      "    positive       0.66      0.77      0.71      3610\n",
      "\n",
      "    accuracy                           0.61      8544\n",
      "   macro avg       0.54      0.53      0.52      8544\n",
      "weighted avg       0.58      0.61      0.59      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.61      0.60       428\n",
      "     neutral       0.33      0.14      0.20       229\n",
      "    positive       0.58      0.73      0.64       444\n",
      "\n",
      "    accuracy                           0.56      1101\n",
      "   macro avg       0.50      0.49      0.48      1101\n",
      "weighted avg       0.53      0.56      0.53      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_classifier = GloveClassifier(hidden_dim=100, epochs=1000, print_every=100, update_glove=False)\n",
    "experiment(glove_classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When setting the embedding to `requires_grad=True` the embedding weights change after training, but not when it's `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 70.56\t0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_classifier = GloveClassifier(hidden_dim=100, epochs=1, print_every=1, update_glove=False)\n",
    "initial_weights = glove_classifier.embed.weight.detach().numpy().copy()\n",
    "glove_classifier.fit(train_texts, train_labels)\n",
    "later_weights = glove_classifier.embed.weight.detach().numpy()\n",
    "\n",
    "(initial_weights == later_weights).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 70.57\t0.41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_classifier = GloveClassifier(hidden_dim=100, epochs=1, print_every=1, update_glove=True)\n",
    "initial_weights = glove_classifier.embed.weight.detach().numpy().copy()\n",
    "glove_classifier.fit(train_texts, train_labels)\n",
    "later_weights = glove_classifier.embed.weight.detach().numpy()\n",
    "\n",
    "(initial_weights == later_weights).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, label_to_id = BOWClassifier.build_vocab(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(classifier):\n",
    "    for text in 'It was a horrible disgusting movie', 'it was ok', 'It was an amazing movie!':\n",
    "        print(text)\n",
    "        print(classifier.predict(text))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 195.27\t0.74\n",
      "Epoch 10: 151.04\t0.83\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.92      0.87      3310\n",
      "     neutral       0.93      0.51      0.66      1624\n",
      "    positive       0.84      0.93      0.89      3610\n",
      "\n",
      "    accuracy                           0.85      8544\n",
      "   macro avg       0.87      0.79      0.80      8544\n",
      "weighted avg       0.85      0.85      0.84      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.72      0.68       428\n",
      "     neutral       0.36      0.07      0.12       229\n",
      "    positive       0.63      0.81      0.70       444\n",
      "\n",
      "    accuracy                           0.62      1101\n",
      "   macro avg       0.54      0.53      0.50      1101\n",
      "weighted avg       0.57      0.62      0.57      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BOWClassifier(word_to_id, label_to_id, epochs=10)\n",
    "experiment(classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 195.26\t0.74\n",
      "Epoch 10: 150.96\t0.83\n",
      "Epoch 15: 124.15\t0.87\n",
      "Epoch 20: 105.18\t0.90\n",
      "Epoch 25: 90.82\t0.92\n",
      "Epoch 30: 79.49\t0.93\n",
      "Epoch 35: 70.36\t0.94\n",
      "Epoch 40: 62.71\t0.95\n",
      "Epoch 45: 56.27\t0.96\n",
      "Epoch 50: 50.82\t0.96\n",
      "\n",
      "## Train ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.98      0.97      3310\n",
      "     neutral       0.96      0.90      0.93      1624\n",
      "    positive       0.97      0.98      0.98      3610\n",
      "\n",
      "    accuracy                           0.96      8544\n",
      "   macro avg       0.96      0.95      0.96      8544\n",
      "weighted avg       0.96      0.96      0.96      8544\n",
      "\n",
      "## Dev ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.68      0.67       428\n",
      "     neutral       0.32      0.21      0.26       229\n",
      "    positive       0.66      0.74      0.69       444\n",
      "\n",
      "    accuracy                           0.61      1101\n",
      "   macro avg       0.54      0.54      0.54      1101\n",
      "weighted avg       0.58      0.61      0.59      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BOWClassifier(word_to_id, label_to_id, epochs=50)\n",
    "experiment(classifier, train_texts, train_labels, dev_texts, dev_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
