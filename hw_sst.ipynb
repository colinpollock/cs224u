{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Stanford Sentiment Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm tracking all results in [this spreadsheet](https://docs.google.com/spreadsheets/d/1Bc3s89Vxk5ZnKHeK2BEimoePegCc0B-Mc9tARtrQkVo/edit#gid=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Methodological note](#Methodological-note)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [A softmax baseline](#A-softmax-baseline)\n",
    "1. [RNNClassifier wrapper](#RNNClassifier-wrapper)\n",
    "1. [Error analysis](#Error-analysis)\n",
    "1. [Homework questions](#Homework-questions)\n",
    "  1. [Reproducing Socher et al.'s NaiveBayes baselines [2 points]](#Reproducing-Socher-et-al.'s-NaiveBayes-baselines-[2-points])\n",
    "  1. [Sentiment words alone [2 points]](#Sentiment-words-alone-[2-points])\n",
    "  1. [A more powerful vector-summing baseline [2 points]](#A-more-powerful-vector-summing-baseline-[2-points])\n",
    "  1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bake-off [1 point]](#Bake-off-[1-point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This homework and associated bake-off are devoted to the Stanford Sentiment Treebank (SST). The homework questions ask you to implement some baseline systems, and the bake-off challenge is to define a system that does extremely well at the SST task.\n",
    "\n",
    "We'll focus on the ternary task as defined by `sst.ternary_class_func`.\n",
    "\n",
    "The SST test set will be used for the bake-off evaluation. This dataset is already publicly distributed, so we are counting on people not to cheat by develping their models on the test set. You must do all your development without using the test set at all, and then evaluate exactly once on the test set and turn in the results, with no further system tuning or additional runs. __Much of the scientific integrity of our field depends on people adhering to this honor code__. \n",
    "\n",
    "Our only additional restriction is that __you cannot make any use of the subtree labels__. This corresponds to the 'Root' condition in the paper. As we discussed in class, the subtree labels are a really interesting feature of SST, but bringing them in results in a substantially different learning problem.\n",
    "\n",
    "One of our goals for this homework and bake-off is to encourage you to engage in __the basic development cycle for supervised models__, in which you\n",
    "\n",
    "1. Write a new feature function. We recommend starting with something simple.\n",
    "1. Use `sst.experiment` to evaluate your new feature function, with at least `fit_softmax_classifier`.\n",
    "1. If you have time, compare your feature function with `unigrams_phi` using `sst.compare_models` or `sst.compare_models_mcnemar`. (For discussion, see [this notebook section](sst_02_hand_built_features.ipynb#Statistical-comparison-of-classifier-models).)\n",
    "1. Return to step 1, or stop the cycle and conduct a more rigorous evaluation with hyperparameter tuning and assessment on the `dev` set.\n",
    "\n",
    "[Error analysis](#Error-analysis) is one of the most important methods for steadily improving a system, as it facilitates a kind of human-powered hill-climbing on your ultimate objective. Often, it takes a careful human analyst just a few examples to spot a major pattern that can lead to a beneficial change to the feature representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodological note\n",
    "\n",
    "You don't have to use the experimental framework defined below (based on `sst`). However, if you don't use `sst.experiment` as below, then make sure you're training only on `train`, evaluating on `dev`, and that you report with \n",
    "\n",
    "```\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_dev, predictions)\n",
    "```\n",
    "where `y_dev = [y for tree, y in sst.dev_reader(class_func=sst.ternary_class_func)]`. We'll focus on the value at `macro avg` under `f1-score` in these reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "See [the first notebook in this unit](sst_01_overview.ipynb#Set-up) for set-up instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tree import Tree\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sst\n",
    "from torch import nn, functional as F\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "from torch_tree_nn import TorchTreeNN\n",
    "import utils\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import opinion_lexicon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import diskcache\n",
    "# import spacy\n",
    "# from spacy.tokens import Doc\n",
    "import functools\n",
    "import torch\n",
    "from functools import lru_cache\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "def display_html(html):\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3f87b4af884e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_spacy_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiskcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'__spacy_cache__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"Return a spaCy doc for the given text.\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "_spacy_cache = diskcache.Cache(directory='__spacy_cache__')\n",
    "_nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"Return a spaCy doc for the given text.\n",
    "    Docs are cached to disk (very inefficiently, but it should work for development.)\n",
    "    \"\"\"\n",
    "    doc_as_bytes = _spacy_cache.get(text)\n",
    "    \n",
    "    if doc_as_bytes is None:\n",
    "        doc = _nlp(text)\n",
    "        _spacy_cache[text] = doc.to_bytes()\n",
    "    else:\n",
    "        doc = Doc(vocab=_nlp.vocab).from_bytes(doc_as_bytes)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_HOME = os.path.join('data', 'trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A softmax baseline\n",
    "\n",
    "This example is here mainly as a reminder of how to use our experimental framework with linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams_phi(tree):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.tree\n",
    "        The tree to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    Counter\n",
    "        A map from strings to their counts in `tree`. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \n",
    "    \"\"\"\n",
    "    return Counter(tree.leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thin wrapper around `LogisticRegression` for the sake of `sst.experiment`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this isn't really softmax since sklearn is using the one-vs-rest strategy,\n",
    "# training one classifier for each class. We would have to use the 'multinomial' strategy\n",
    "# to actually do softmax. But trying that took a long time and my fan was getting loud so\n",
    "# I didn't actually check performance.\n",
    "def fit_softmax_classifier(X, y, C=1.0):      \n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr',\n",
    "        C=C)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_softmax_with_crossvalidation(X, y):\n",
    "    \"\"\"A MaxEnt model of dataset with hyperparameter \n",
    "    cross-validation. Some notes:\n",
    "        \n",
    "    * 'fit_intercept': whether to include the class bias feature.\n",
    "    * 'C': weight for the regularization term (smaller is more regularized).\n",
    "    * 'penalty': type of regularization -- roughly, 'l1' ecourages small \n",
    "      sparse models, and 'l2' encourages the weights to conform to a \n",
    "      gaussian prior distribution.\n",
    "    \n",
    "    Other arguments can be cross-validated; see \n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear_model.LogisticRegression\n",
    "        A trained model instance, the best model found.\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = LogisticRegression(\n",
    "        fit_intercept=True, \n",
    "        solver='liblinear', \n",
    "        multi_class='auto')\n",
    "    cv = 5\n",
    "    param_grid = {'fit_intercept': [True, False], \n",
    "                  'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                  'penalty': ['l1','l2']}    \n",
    "    best_mod = utils.fit_classifier_with_crossvalidation(\n",
    "        X, y, basemod, cv, param_grid)\n",
    "    return best_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experimental run with some notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.628     0.689     0.657       428\n",
      "     neutral      0.343     0.153     0.211       229\n",
      "    positive      0.629     0.750     0.684       444\n",
      "\n",
      "    accuracy                          0.602      1101\n",
      "   macro avg      0.533     0.531     0.518      1101\n",
      "weighted avg      0.569     0.602     0.575      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax_experiment = sst.experiment(\n",
    "    SST_HOME,\n",
    "    unigrams_phi,                      # Free to write your own!\n",
    "    fit_softmax_classifier,            # Free to write your own!\n",
    "    train_reader=sst.train_reader,     # Fixed by the competition.\n",
    "    assess_reader=sst.dev_reader,      # Fixed until the bake-off.\n",
    "    class_func=sst.ternary_class_func) # Fixed by the bake-off rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`softmax_experiment` contains a lot of information that you can use for analysis; see [this section below](#Error-analysis) for starter code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNClassifier wrapper\n",
    "\n",
    "This section illustrates how to use `sst.experiment` with RNN and TreeNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To featurize examples for an RNN, we just get the words in order, letting the model take care of mapping them into an embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_phi(tree):\n",
    "    return tree.leaves()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model wrapper gets the vocabulary using `sst.get_vocab`. If you want to use pretrained word representations in here, then you can have `fit_rnn_classifier` build that space too; see [this notebook section for details](sst_03_neural_networks.ipynb#Pretrained-embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn_classifier(X, y):    \n",
    "    sst_glove_vocab = utils.get_vocab(X, n_words=10000)     \n",
    "    mod = TorchRNNClassifier(\n",
    "        sst_glove_vocab, \n",
    "        eta=0.05,\n",
    "        embedding=None,\n",
    "        batch_size=1000,\n",
    "        embed_dim=50,\n",
    "        hidden_dim=50,\n",
    "        max_iter=50,\n",
    "        l2_strength=0.001,\n",
    "        bidirectional=True,\n",
    "        hidden_activation=nn.ReLU())\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 50 of 50; error is 2.2185898572206497"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.593     0.666     0.627       428\n",
      "     neutral      0.290     0.205     0.240       229\n",
      "    positive      0.638     0.658     0.647       444\n",
      "\n",
      "   micro avg      0.567     0.567     0.567      1101\n",
      "   macro avg      0.507     0.510     0.505      1101\n",
      "weighted avg      0.548     0.567     0.555      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_experiment = sst.experiment(\n",
    "    SST_HOME,\n",
    "    rnn_phi,\n",
    "    fit_rnn_classifier, \n",
    "    vectorize=False,  # For deep learning, use `vectorize=False`.\n",
    "    assess_reader=sst.dev_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "This section begins to build an error-analysis framework using the dicts returned by `sst.experiment`. These have the following structure:\n",
    "\n",
    "```\n",
    "'model': trained model\n",
    "'train_dataset':\n",
    "   'X': feature matrix\n",
    "   'y': list of labels\n",
    "   'vectorizer': DictVectorizer,\n",
    "   'raw_examples': list of raw inputs, before featurizing   \n",
    "'assess_dataset': same structure as the value of 'train_dataset'\n",
    "'predictions': predictions on the assessment data\n",
    "'metric': `score_func.__name__`, where `score_func` is an `sst.experiment` argument\n",
    "'score': the `score_func` score on the assessment data\n",
    "```\n",
    "The following function just finds mistakes, and returns a `pd.DataFrame` for easy subsequent processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_errors(experiment):\n",
    "    \"\"\"Find mistaken predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment : dict\n",
    "        As returned by `sst.experiment`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    raw_examples = experiment['assess_dataset']['raw_examples']\n",
    "    raw_examples = [\" \".join(tree.leaves()) for tree in raw_examples]\n",
    "    df = pd.DataFrame({\n",
    "        'raw_examples': raw_examples,\n",
    "        'predicted': experiment['predictions'],\n",
    "        'gold': experiment['assess_dataset']['y']})\n",
    "    df['correct'] = df['predicted'] == df['gold']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_analysis = find_errors(softmax_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_examples</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gold</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It 's a lovely film with lovely performances b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No one goes unindicted here , which is probabl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And if you 're not nearly moved to tears by a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A warm , funny , engaging film .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uses sharp humor and insight into human nature...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        raw_examples predicted      gold  \\\n",
       "0  It 's a lovely film with lovely performances b...  positive  positive   \n",
       "1  No one goes unindicted here , which is probabl...  negative   neutral   \n",
       "2  And if you 're not nearly moved to tears by a ...  positive  positive   \n",
       "3                   A warm , funny , engaging film .  positive  positive   \n",
       "4  Uses sharp humor and insight into human nature...  positive  positive   \n",
       "\n",
       "   correct  \n",
       "0     True  \n",
       "1    False  \n",
       "2     True  \n",
       "3     True  \n",
       "4     True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_analysis = find_errors(rnn_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge the sotmax and RNN experiments into a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = softmax_analysis.merge(\n",
    "    rnn_analysis, left_on='raw_examples', right_on='raw_examples')\n",
    "\n",
    "analysis = analysis.drop('gold_y', axis=1).rename(columns={'gold_x': 'gold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code collects a specific subset of examples; small modifications to its structure will give you different interesting subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples where the softmax model is correct, the RNN is not,\n",
    "# and the gold label is 'positive'\n",
    "\n",
    "error_group = analysis[\n",
    "    (analysis['predicted_x'] == analysis['gold'])\n",
    "    &\n",
    "    (analysis['predicted_y'] != analysis['gold'])    \n",
    "    &\n",
    "    (analysis['gold'] == 'positive')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "An interesting story with a pertinent -LRB- cinematically unique -RRB- message , told fairly well and scored to perfection , I found myself struggling to put my finger on that elusive `` missing thing . ''\n",
      "======================================================================\n",
      "Having had the good sense to cast actors who are , generally speaking , adored by the movie-going public , Khouri then gets terrific performances from them all .\n",
      "======================================================================\n",
      "But it still jingles in the pocket .\n",
      "======================================================================\n",
      "That is a compliment to Kuras and Miller .\n",
      "======================================================================\n",
      "-LRB- Næs -RRB- directed the stage version of Elling , and gets fine performances from his two leads who originated the characters on stage .\n"
     ]
    }
   ],
   "source": [
    "for ex in error_group['raw_examples'].sample(5):\n",
    "    print(\"=\"*70)\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework questions\n",
    "\n",
    "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing Socher et al.'s NaiveBayes baselines [2 points]\n",
    "\n",
    "[Socher et al.](https://www.aclweb.org/anthology/D13-1170/) compare against (among other models) a NaiveBayes baseline with bigram features. See how close you can come to reproducing the performance of that model on the binary, root-only problem (values in the rightmost column of their Table 1, rows 1 and 3).\n",
    "\n",
    "Specific tasks:\n",
    "\n",
    "1. Write a bigrams feature function called `bigrams_phi` on the model of `unigrams_phi`. The included function `test_bigrams_phi` should help verify that you've done this correctly.\n",
    "1. Write a function `fit_nb_classifier` that serves as a wrapper for `sklearn.naive_bayes.MultinomialNB`, which you can use with all its default arguments or change them as you see fit.\n",
    "1. Use `sst.experiment` to run the experiments, assessing against `sst.dev_reader`.\n",
    "\n",
    "Submit all the code you write for this, including any new import statements, and make sure your notebook embeds the output from running the code in step 3.\n",
    "\n",
    "__A note on performance__: in our experience, the bigrams Naive Bayes model gets around 0.75. It's fine to submit answers with comparable numbers; the Socher et al. baselines are very strong. We're not evaluating how good your model is; we want to see your code, and we're interested to see what the range of F1 scores is across the whole class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.774     0.696     0.733       428\n",
      "    positive      0.733     0.804     0.767       444\n",
      "\n",
      "   micro avg      0.751     0.751     0.751       872\n",
      "   macro avg      0.754     0.750     0.750       872\n",
      "weighted avg      0.753     0.751     0.750       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### YOUR CODE HERE\n",
    "def test_bigrams_phi(func):\n",
    "    \"\"\"`func` should be `bigrams_phi`.\"\"\"\n",
    "    tree = Tree.fromstring(\"\"\"(4 (2 NLU) (4 (2 is) (4 amazing)))\"\"\")\n",
    "    result = bigrams_phi(tree)\n",
    "    expected = {('<S>', 'NLU'): 1, \n",
    "                ('NLU', 'is'): 1, \n",
    "                ('is', 'amazing'): 1, \n",
    "                ('amazing', '</S>'): 1}\n",
    "    assert result == expected, \\\n",
    "        \"Expected {}\\nGot {}\".format(expected, result)\n",
    "def ngrams(tokens, n):\n",
    "    for i in range(0, len(tokens) - n + 1):\n",
    "        yield tuple(tokens[i: i+n])\n",
    "\n",
    "def bigrams_phi(tree):\n",
    "    tokens = ['<S>'] + tree.leaves() + ['</S>']\n",
    "    bigrams = ngrams(tokens, 2)\n",
    "    \n",
    "    return Counter(bigrams)\n",
    "\n",
    "test_bigrams_phi(bigrams_phi)\n",
    "\n",
    "\n",
    "def fit_nb_classifier(X, y):        \n",
    "    mod = MultinomialNB()\n",
    "    mod.fit(X, y)\n",
    "    return mod\n",
    "\n",
    "nb_experiment = sst.experiment(\n",
    "    SST_HOME,\n",
    "    bigrams_phi,\n",
    "    fit_nb_classifier,\n",
    "    class_func=sst.binary_class_func,\n",
    "    assess_reader=sst.dev_reader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment words alone [2 points]\n",
    "\n",
    "NLTK includes an easy interface to [Minqing Hu and Bing Liu's __Opinion Lexicon__](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), which consists of a list of positive words and a list of negative words. How much of the ternary SST story does this lexicon tell?\n",
    "\n",
    "For this problem, submit code to do the following:\n",
    "\n",
    "1. Create a feature function `op_unigrams` on the model of `unigrams_phi` above, but filtering the vocabulary to just items that are members of the Opinion Lexicon. Submit this feature function.\n",
    "\n",
    "1. Evaluate your feature function with `sst.experiment`, with all the same parameters as were used to create `softmax_experiment` in [A softmax baseline](#A-softmax-baseline) above, except of course for the feature function.\n",
    "\n",
    "1. Use `utils.mcnemar` to compare your feature function with the results in `softmax_experiment`. The information you need for this is in `softmax_experiment` and your own `sst.experiment` results. Submit your evaluation code. You can assume `softmax_experiment` is already in memory, but your code should create the other objects necessary for this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.553     0.752     0.638       428\n",
      "     neutral      0.179     0.031     0.052       229\n",
      "    positive      0.615     0.664     0.639       444\n",
      "\n",
      "   micro avg      0.567     0.567     0.567      1101\n",
      "   macro avg      0.449     0.482     0.443      1101\n",
      "weighted avg      0.500     0.567     0.516      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use set for fast membership checking:\n",
    "positive = set(opinion_lexicon.positive())\n",
    "negative = set(opinion_lexicon.negative())\n",
    "sentiment_words = positive | negative\n",
    "\n",
    "##### YOUR CODE HERE\n",
    "def op_unigrams(tree):\n",
    "    return {\n",
    "        word: freq\n",
    "        for (word, freq) in unigrams_phi(tree).items()\n",
    "        if word in sentiment_words\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "opinion_experiment = sst.experiment(\n",
    "    SST_HOME,\n",
    "    op_unigrams,                    \n",
    "    fit_softmax_classifier,\n",
    "    assess_reader=sst.dev_reader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.328413284132841, 0.020980477345314247)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = opinion_experiment['assess_dataset']['y']\n",
    "assert y_true == softmax_experiment['assess_dataset']['y']\n",
    "\n",
    "utils.mcnemar(y_true, softmax_experiment['predictions'], opinion_experiment['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more powerful vector-summing baseline [2 points]\n",
    "\n",
    "In [Distributed representations as features](sst_03_neural_networks.ipynb#Distributed-representations-as-features), we looked at a baseline for the ternary SST problem in which each example is modeled as the sum of its 50-dimensional GloVe representations. A `LogisticRegression` model was used for prediction. A neural network might do better with these representations, since there might be complex relationships between the input feature dimensions that a linear classifier can't learn. \n",
    "\n",
    "To address this question, rerun the experiment with `TorchShallowNeuralClassifier` as the classifier. Specs:\n",
    "* Use `sst.experiment` to conduct the experiment. \n",
    "* Using 3-fold cross-validation, exhaustively explore this set of hyperparameter combinations:\n",
    "  * The hidden dimensionality at 50, 100, and 200.\n",
    "  * The hidden activation function as `nn.Tanh` or `nn.ReLU`.\n",
    "* (For all other parameters to `TorchShallowNeuralClassifier`, use the defaults.)\n",
    "\n",
    "For this problem, submit code to do the following:\n",
    "\n",
    "1. Your model wrapper function around `TorchShallowNeuralClassifier`. This function should implement the requisite cross-validation; see [this notebook section](sst_02_hand_built_features.ipynb#Hyperparameter-search) for examples.\n",
    "1. The classification report as printed by `sst.experiment`. (This will print out when you run `sst.experiment`. That print-out suffices.)\n",
    "2. The optimal hyperparameters chosen in your experiment. (This too will print out when you run `sst.experiment`. The print-out again suffices.)\n",
    "\n",
    "We're not evaluating the quality of your model. (We've specified the protocols completely, but there will still be variation in the results.) However, the primary goal of this question is to get you thinking more about this strikingly good baseline feature representation scheme for SST, so we're sort of hoping you feel compelled to try out variations on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATA_HOME = 'data'\n",
    "_GLOVE_HOME = os.path.join(_DATA_HOME, 'glove.6B')\n",
    "\n",
    "glove_lookup = utils.glove2dict(\n",
    "    os.path.join(_GLOVE_HOME, 'glove.6B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsm_leaves_phi(tree, lookup, np_func=np.sum):\n",
    "    \"\"\"Represent `tree` as a combination of the vector of its words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.Tree   \n",
    "    lookup : dict\n",
    "        From words to vectors.\n",
    "    np_func : function (default: np.sum)\n",
    "        A numpy matrix operation that can be applied columnwise, \n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that \n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a \n",
    "        fixed length, no matter what the size of the tree is.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array, dimension `X.shape[1]`\n",
    "            \n",
    "    \"\"\"      \n",
    "    allvecs = np.array([lookup[w] for w in tree.leaves() if w in lookup])    \n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(lookup.values())))\n",
    "        feats = np.zeros(dim)\n",
    "    else:       \n",
    "        feats = np_func(allvecs, axis=0)      \n",
    "    return feats\n",
    "\n",
    "def glove_leaves_phi(tree, np_func=np.sum):\n",
    "    return vsm_leaves_phi(tree, glove_lookup, np_func=np_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### YOUR CODE HERE\n",
    "X_rnn_train, y_rnn_train = sst.build_rnn_dataset(\n",
    "    SST_HOME, sst.train_reader, class_func=sst.ternary_class_func)\n",
    "\n",
    "def fit_shallow_nn_classifier(X, y):\n",
    "    sst_train_vocab = utils.get_vocab(X_rnn_train, n_words=1000)\n",
    "    rnn = TorchRNNClassifier(sst_train_vocab)\n",
    "    rnn.fit(X, y)\n",
    "    return rnn\n",
    "\n",
    "# sst.experiment(SST_HOME, glove_leaves_phi, fit_shallow_nn_classifier, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_human_eval(reader, sample_size):\n",
    "    records = []\n",
    "    for tree, label in reader:\n",
    "        text = tree.leaves()\n",
    "        records.append({\n",
    "            'label': label,\n",
    "            'text': ' '.join(tree.leaves()),\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records).sample(sample_size)\n",
    "\n",
    "human_eval_raw_df = make_human_eval(sst.train_reader(SST_HOME), 100)\n",
    "human_eval_raw_df.to_clipboard()\n",
    "\n",
    "# http://docs.google.com/spreadsheets/d/1FKuy-muIR3f3_rT4EUGTk-_bVUStXEIPXDSrtf-imIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total agreement on 5-way: 51%\n",
      "Total agreement on 3-way: 78%\n"
     ]
    }
   ],
   "source": [
    "human_eval_df = pd.read_csv('sentiment_human_eval.tsv', sep='\\t', index_col=0)\n",
    "human_eval_df.columns = ['label_5', 'my_label_5', 'text']\n",
    "\n",
    "human_eval_df['label_3'] = human_eval_df.label_5.astype(str).apply(sst.ternary_class_func)\n",
    "human_eval_df['my_label_3'] = human_eval_df.my_label_5.astype(str).apply(sst.ternary_class_func)\n",
    "\n",
    "human_eval_df['is_correct'] = human_eval_df.label_3 == human_eval_df.my_label_3\n",
    "\n",
    "\n",
    "print('Total agreement on 5-way: {:.0f}%'.format((human_eval_df.label_5 == human_eval_df.my_label_5).mean() * 100))\n",
    "print('Total agreement on 3-way: {:.0f}%'.format(human_eval_df.is_correct.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_5</th>\n",
       "      <th>my_label_5</th>\n",
       "      <th>text</th>\n",
       "      <th>label_3</th>\n",
       "      <th>my_label_3</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The actresses may have worked up a back story for the women they portray so convincingly , but viewers do n't get enough of that background for the characters to be involving as individuals rather than types .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The stars may be college kids , but the subject matter is as adult as you can get : the temptations of the flesh are unleashed by a slightly crazed , overtly determined young woman and a one-night swim turns into an ocean of trouble .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It depends on how well flatulence gags fit into your holiday concept .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Well , it 's not as pathetic as The Animal .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparently writer-director Attal thought he need only cast himself and his movie-star wife sitting around in their drawers to justify a film .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Nicole Kidman evolved from star to superstar some time over the past year , which means that Birthday Girl is the kind of quirkily appealing minor movie she might not make for a while .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Directors John Musker and Ron Clements , the team behind The Little Mermaid , have produced sparkling retina candy , but they are n't able to muster a lot of emotional resonance in the cold vacuum of space .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Even these tales of just seven children seem at times too many , although in reality they are not enough .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A Sha-Na-Na sketch punctuated with graphic violence .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Walsh ca n't quite negotiate the many inconsistencies in Janice 's behavior or compensate for them by sheer force of charm .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>It 's like Rocky and Bullwinkle on Speed , but that 's neither completely enlightening , nor does it catch the intensity of the movie 's strangeness .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>An uncomfortable experience , but one as brave and challenging as you could possibly expect these days from American cinema .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>If you 're looking for a tale of Brits behaving badly , watch Snatch again .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Count on his movie to work at the back of your neck long after you leave the theater .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>An average B-movie with no aspirations to be anything more .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The movie is essentially a series of fleetingly interesting actors ' moments .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Two hours of sepia-tinted heavy metal images and surround sound effects of people moaning .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>... by the time it 's done with us , Mira Nair 's new movie has its audience giddy with the delight of discovery , of having been immersed in a foreign culture only to find that human nature is pretty much the same all over .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>... somehow manages to escape the shackles of its own clichés to be the best espionage picture to come out in weeks .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunshine State surveys the landscape and assesses the issues with a clear passion for sociology .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Take any 12-year-old boy to see this picture , and he 'll be your slave for a year .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This one is not nearly as dreadful as expected .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_5  my_label_5  \\\n",
       "884                         \n",
       "4457        2           1   \n",
       "1091        3           2   \n",
       "2117        2           1   \n",
       "7266        2           1   \n",
       "6400        2           1   \n",
       "2268        3           2   \n",
       "4181        2           1   \n",
       "1684        2           1   \n",
       "7995        2           1   \n",
       "4252        2           1   \n",
       "3765        1           2   \n",
       "1651        3           1   \n",
       "6422        2           1   \n",
       "3428        2           3   \n",
       "5249        1           2   \n",
       "7096        2           1   \n",
       "8168        2           1   \n",
       "3058        4           2   \n",
       "2298        3           1   \n",
       "5372        2           3   \n",
       "1879        3           2   \n",
       "1555        3           2   \n",
       "\n",
       "                                                                                                                                                                                                                                            text  \\\n",
       "884                                                                                                                                                                                                                                                \n",
       "4457                           The actresses may have worked up a back story for the women they portray so convincingly , but viewers do n't get enough of that background for the characters to be involving as individuals rather than types .   \n",
       "1091  The stars may be college kids , but the subject matter is as adult as you can get : the temptations of the flesh are unleashed by a slightly crazed , overtly determined young woman and a one-night swim turns into an ocean of trouble .   \n",
       "2117                                                                                                                                                                      It depends on how well flatulence gags fit into your holiday concept .   \n",
       "7266                                                                                                                                                                                                Well , it 's not as pathetic as The Animal .   \n",
       "6400                                                                                              Apparently writer-director Attal thought he need only cast himself and his movie-star wife sitting around in their drawers to justify a film .   \n",
       "2268                                                   Nicole Kidman evolved from star to superstar some time over the past year , which means that Birthday Girl is the kind of quirkily appealing minor movie she might not make for a while .   \n",
       "4181                             Directors John Musker and Ron Clements , the team behind The Little Mermaid , have produced sparkling retina candy , but they are n't able to muster a lot of emotional resonance in the cold vacuum of space .   \n",
       "1684                                                                                                                                  Even these tales of just seven children seem at times too many , although in reality they are not enough .   \n",
       "7995                                                                                                                                                                                       A Sha-Na-Na sketch punctuated with graphic violence .   \n",
       "4252                                                                                                                Walsh ca n't quite negotiate the many inconsistencies in Janice 's behavior or compensate for them by sheer force of charm .   \n",
       "3765                                                                                      It 's like Rocky and Bullwinkle on Speed , but that 's neither completely enlightening , nor does it catch the intensity of the movie 's strangeness .   \n",
       "1651                                                                                                               An uncomfortable experience , but one as brave and challenging as you could possibly expect these days from American cinema .   \n",
       "6422                                                                                                                                                                If you 're looking for a tale of Brits behaving badly , watch Snatch again .   \n",
       "3428                                                                                                                                                      Count on his movie to work at the back of your neck long after you leave the theater .   \n",
       "5249                                                                                                                                                                                An average B-movie with no aspirations to be anything more .   \n",
       "7096                                                                                                                                                              The movie is essentially a series of fleetingly interesting actors ' moments .   \n",
       "8168                                                                                                                                                 Two hours of sepia-tinted heavy metal images and surround sound effects of people moaning .   \n",
       "3058           ... by the time it 's done with us , Mira Nair 's new movie has its audience giddy with the delight of discovery , of having been immersed in a foreign culture only to find that human nature is pretty much the same all over .   \n",
       "2298                                                                                                                       ... somehow manages to escape the shackles of its own clichés to be the best espionage picture to come out in weeks .   \n",
       "5372                                                                                                                                           Sunshine State surveys the landscape and assesses the issues with a clear passion for sociology .   \n",
       "1879                                                                                                                                                        Take any 12-year-old boy to see this picture , and he 'll be your slave for a year .   \n",
       "1555                                                                                                                                                                                            This one is not nearly as dreadful as expected .   \n",
       "\n",
       "       label_3 my_label_3  is_correct  \n",
       "884                                    \n",
       "4457   neutral   negative       False  \n",
       "1091  positive    neutral       False  \n",
       "2117   neutral   negative       False  \n",
       "7266   neutral   negative       False  \n",
       "6400   neutral   negative       False  \n",
       "2268  positive    neutral       False  \n",
       "4181   neutral   negative       False  \n",
       "1684   neutral   negative       False  \n",
       "7995   neutral   negative       False  \n",
       "4252   neutral   negative       False  \n",
       "3765  negative    neutral       False  \n",
       "1651  positive   negative       False  \n",
       "6422   neutral   negative       False  \n",
       "3428   neutral   positive       False  \n",
       "5249  negative    neutral       False  \n",
       "7096   neutral   negative       False  \n",
       "8168   neutral   negative       False  \n",
       "3058  positive    neutral       False  \n",
       "2298  positive   negative       False  \n",
       "5372   neutral   positive       False  \n",
       "1879  positive    neutral       False  \n",
       "1555  positive    neutral       False  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_eval_df[~human_eval_df.is_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_eval_df.groupby('label_5').is_correct.mean().plot.bar(title='Correct Rate by Fine-Grained Gold Label')\n",
    "plt.xlabel('Fine-Grained Label')\n",
    "_ = plt.ylabel('My Percent Correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H4>Confusion Matrix between my judgments and and the gold data<H4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>my_label_3</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>36%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11%</td>\n",
       "      <td>4%</td>\n",
       "      <td>2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2%</td>\n",
       "      <td>5%</td>\n",
       "      <td>37%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "my_label_3 negative neutral positive\n",
       "label_3                             \n",
       "negative        36%      2%       0%\n",
       "neutral         11%      4%       2%\n",
       "positive         2%      5%      37%"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_confusion_matrix_for_my_eval(human_eval_df):\n",
    "    crosstab = pd.crosstab(human_eval_df.label_3, human_eval_df.my_label_3)\n",
    "    total = crosstab.sum().sum()\n",
    "\n",
    "    return crosstab.divide(total).applymap(lambda num: '{}%'.format(int(num * 100)))\n",
    "\n",
    "display_html(\"<H4>Confusion Matrix between my judgments and and the gold data<H4>\")\n",
    "show_confusion_matrix_for_my_eval(human_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from Human Eval ##\n",
    "* For the ternary task I only got 78% of the 100 examples correct.\n",
    "* Only 2% of my errors were from confusing positive and negative.\n",
    "* The biggest error type at 11% was me thinking gold neutral labels were negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(featurize_func, fit_func, verbose=True, vectorize=True):\n",
    "    \"\"\"Wrapper of `sst.experiment` that computes the score against the dev and train sets.\"\"\"\n",
    "    score_func = utils.safe_macro_f1\n",
    "    exp = sst.experiment(\n",
    "        SST_HOME,\n",
    "        featurize_func,\n",
    "        fit_func,\n",
    "        class_func=sst.ternary_class_func,\n",
    "        assess_reader=sst.dev_reader,\n",
    "        score_func=score_func,\n",
    "        verbose=False,\n",
    "        vectorize=vectorize\n",
    "    )\n",
    "        \n",
    "    exp['dev_predictions'] = exp['predictions']\n",
    "    exp['dev_score'] = exp['score']\n",
    "    del exp['predictions']\n",
    "    del exp['score']\n",
    "    \n",
    "    model = exp['model']\n",
    "    train_predictions = model.predict(exp['train_dataset']['X'])\n",
    "    exp['train_predictions'] = train_predictions\n",
    "    \n",
    "    exp['train_score'] = score_func(exp['train_dataset']['y'], train_predictions)\n",
    "    \n",
    "    if verbose is True:\n",
    "        display_html(\"<H2>Train</H2>\")\n",
    "        print(classification_report(exp['train_dataset']['y'], train_predictions, digits=3))\n",
    "        \n",
    "\n",
    "        display_html(\"<H2>Dev</H2>\")\n",
    "        print(classification_report(exp['assess_dataset']['y'], exp['dev_predictions'], digits=3))\n",
    "\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your original system [3 points]\n",
    "\n",
    "Your task is to develop an original model for the SST ternary problem, using only the root-level labels (again, __you cannot make any use of the subtree labels__). There are many options. If you spend more than a few hours on this homework problem, you should consider letting it grow into your final project! Here are some relatively manageable ideas that you might try:\n",
    "\n",
    "1. We didn't systematically evaluate the `bidirectional` option to the `TorchRNNClassifier`. Similarly, that model could be tweaked to allow multiple LSTM layers (at present there is only one), and you could try adding layers to the classifier portion of the model as well.\n",
    "\n",
    "1. We've already glimpsed the power of rich initial word representations, and later in the course we'll see that smart initialization usually leads to a performance gain in NLP, so you could perhaps achieve a winning entry with a simple model that starts in a great place.\n",
    "\n",
    "1. The [practical introduction to contextual word representations](contextualreps.ipynb) (to be discussed later in the quarter) covers pretrained representations and interfaces that are likely to boost the performance of any system.\n",
    "\n",
    "1. The `TreeNN` and `TorchTreeNN` don't perform all that well, and this could be for the same reason that RNNs don't peform well: the gradient signal doesn't propagate reliably down inside very deep trees. [Tai et al. 2015](https://aclanthology.info/papers/P15-1150/p15-1150) sought to address this with TreeLSTMs, which are fairly easy to implement in PyTorch.\n",
    "\n",
    "1. In the [distributed representations as features](#Distributed-representations-as-features) section, we just summed  all of the leaf-node GloVe vectors to obtain a fixed-dimensional representation for all sentences. This ignores all of the tree structure. See if you can do better by paying attention to the binary tree structure: write a function `glove_subtree_phi` that obtains a vector representation for each subtree by combining the vectors of its daughters, with the leaf nodes again given by GloVe (any dimension you like) and the full representation of the sentence given by the final vector obtained by this recursive process. You can decide on how you combine the vectors. \n",
    "\n",
    "1. If you have a lot of computing resources, then you can fire off a large hyperparameter search over many parameter values. All the model classes for this course are compatible with the `scikit-learn` and [scikit-optimize](https://scikit-optimize.github.io) methods, because they define the required functions for getting and setting parameters.\n",
    "\n",
    "We want to emphasize that this needs to be an __original__ system. It doesn't suffice to download code from the Web, retrain, and submit. You can build on others' code, but you have to do something new and meaningful with it.\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your system description in this cell.\n",
    "# Please do not remove this comment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.386     0.327     0.354      3310\n",
      "     neutral      0.184     0.323     0.234      1624\n",
      "    positive      0.412     0.329     0.366      3610\n",
      "\n",
      "   micro avg      0.327     0.327     0.327      8544\n",
      "   macro avg      0.327     0.326     0.318      8544\n",
      "weighted avg      0.359     0.327     0.336      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.371     0.308     0.337       428\n",
      "     neutral      0.213     0.349     0.265       229\n",
      "    positive      0.411     0.342     0.373       444\n",
      "\n",
      "   micro avg      0.331     0.331     0.331      1101\n",
      "   macro avg      0.332     0.333     0.325      1101\n",
      "weighted avg      0.354     0.331     0.337      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_random_classifier(X, y):\n",
    "    model = DummyClassifier('uniform')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "random_classifier_experiment = experiment(unigrams_phi, fit_random_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.000     0.000     0.000      3310\n",
      "     neutral      0.000     0.000     0.000      1624\n",
      "    positive      0.423     1.000     0.594      3610\n",
      "\n",
      "   micro avg      0.423     0.423     0.423      8544\n",
      "   macro avg      0.141     0.333     0.198      8544\n",
      "weighted avg      0.179     0.423     0.251      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.000     0.000     0.000       428\n",
      "     neutral      0.000     0.000     0.000       229\n",
      "    positive      0.403     1.000     0.575       444\n",
      "\n",
      "   micro avg      0.403     0.403     0.403      1101\n",
      "   macro avg      0.134     0.333     0.192      1101\n",
      "weighted avg      0.163     0.403     0.232      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_most_common_class_classifier(X, y):\n",
    "    model = DummyClassifier('prior')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "most_common_class_experiment = experiment(unigrams_phi, fit_most_common_class_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.820     0.953     0.881      3310\n",
      "     neutral      0.990     0.481     0.647      1624\n",
      "    positive      0.870     0.942     0.905      3610\n",
      "\n",
      "   micro avg      0.858     0.858     0.858      8544\n",
      "   macro avg      0.893     0.792     0.811      8544\n",
      "weighted avg      0.873     0.858     0.847      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.635     0.757     0.691       428\n",
      "     neutral      0.500     0.057     0.102       229\n",
      "    positive      0.634     0.806     0.710       444\n",
      "\n",
      "   micro avg      0.631     0.631     0.631      1101\n",
      "   macro avg      0.590     0.540     0.501      1101\n",
      "weighted avg      0.606     0.631     0.576      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams_nb_experiment = experiment(unigrams_phi, fit_nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.945     0.983     0.964      3310\n",
      "     neutral      0.981     0.862     0.918      1624\n",
      "    positive      0.963     0.980     0.971      3610\n",
      "\n",
      "   micro avg      0.959     0.959     0.959      8544\n",
      "   macro avg      0.963     0.942     0.951      8544\n",
      "weighted avg      0.959     0.959     0.958      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.628     0.689     0.657       428\n",
      "     neutral      0.343     0.153     0.211       229\n",
      "    positive      0.629     0.750     0.684       444\n",
      "\n",
      "   micro avg      0.602     0.602     0.602      1101\n",
      "   macro avg      0.533     0.531     0.518      1101\n",
      "weighted avg      0.569     0.602     0.575      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams_softmax_experiment = experiment(unigrams_phi, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.979     0.998     0.988      3310\n",
      "     neutral      0.999     0.936     0.967      1624\n",
      "    positive      0.986     0.996     0.991      3610\n",
      "\n",
      "   micro avg      0.985     0.985     0.985      8544\n",
      "   macro avg      0.988     0.977     0.982      8544\n",
      "weighted avg      0.986     0.985     0.985      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.600     0.678     0.637       428\n",
      "     neutral      0.350     0.031     0.056       229\n",
      "    positive      0.592     0.797     0.679       444\n",
      "\n",
      "   micro avg      0.591     0.591     0.591      1101\n",
      "   macro avg      0.514     0.502     0.457      1101\n",
      "weighted avg      0.545     0.591     0.533      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigrams_nb_experiment = experiment(bigrams_phi, fit_nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.999     1.000     0.999      3310\n",
      "     neutral      1.000     0.994     0.997      1624\n",
      "    positive      0.999     1.000     0.999      3610\n",
      "\n",
      "   micro avg      0.999     0.999     0.999      8544\n",
      "   macro avg      0.999     0.998     0.999      8544\n",
      "weighted avg      0.999     0.999     0.999      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.570     0.614     0.592       428\n",
      "     neutral      0.319     0.066     0.109       229\n",
      "    positive      0.572     0.764     0.654       444\n",
      "\n",
      "   micro avg      0.560     0.560     0.560      1101\n",
      "   macro avg      0.487     0.481     0.451      1101\n",
      "weighted avg      0.519     0.560     0.516      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigrams_softmax_experiment = experiment(bigrams_phi, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.627     0.861     0.726      3310\n",
      "     neutral      0.881     0.187     0.308      1624\n",
      "    positive      0.756     0.766     0.761      3610\n",
      "\n",
      "   micro avg      0.692     0.692     0.692      8544\n",
      "   macro avg      0.755     0.604     0.598      8544\n",
      "weighted avg      0.730     0.692     0.661      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.553     0.752     0.638       428\n",
      "     neutral      0.179     0.031     0.052       229\n",
      "    positive      0.615     0.664     0.639       444\n",
      "\n",
      "   micro avg      0.567     0.567     0.567      1101\n",
      "   macro avg      0.449     0.482     0.443      1101\n",
      "weighted avg      0.500     0.567     0.516      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sentiment_words = set(opinion_lexicon.positive()) | set(opinion_lexicon.negative())\n",
    "\n",
    "def opinion_unigrams(tree):\n",
    "    return {\n",
    "        word: freq\n",
    "        for (word, freq) in unigrams_phi(tree).items()\n",
    "        if word in sentiment_words\n",
    "        \n",
    "    }\n",
    "\n",
    "opinion_unigrams_softmax_experiment = experiment(opinion_unigrams, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.768     0.991     0.865      3310\n",
      "     neutral      0.999     0.649     0.787      1624\n",
      "    positive      0.970     0.865     0.915      3610\n",
      "\n",
      "   micro avg      0.873     0.873     0.873      8544\n",
      "   macro avg      0.913     0.835     0.856      8544\n",
      "weighted avg      0.897     0.873     0.871      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.479     0.743     0.582       428\n",
      "     neutral      0.150     0.013     0.024       229\n",
      "    positive      0.588     0.552     0.569       444\n",
      "\n",
      "   micro avg      0.514     0.514     0.514      1101\n",
      "   macro avg      0.405     0.436     0.392      1101\n",
      "weighted avg      0.454     0.514     0.461      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def opinion_bigrams(tree):\n",
    "    return {\n",
    "        bigram: freq\n",
    "        for (bigram, freq) in bigrams_phi(tree).items()\n",
    "        if any(word in _sentiment_words for word in bigram)\n",
    "    \n",
    "    }\n",
    "    \n",
    "    \n",
    "opinion_bigrams_softmax_experiment = experiment(opinion_bigrams, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_tree(tree):\n",
    "    sentence = ' '.join(tree.leaves())\n",
    "    replacements = [\n",
    "        (\" 's\", \"'s\"),\n",
    "        (' .', '.'),\n",
    "        (' ,', ','),\n",
    "        (\"`` \", \"'\"),\n",
    "        (\" ''\", \"'\"),\n",
    "        (\" 'm\", \"'m\"),\n",
    "        (\" 've\", \"'ve\"),\n",
    "        (\" 't\", \"'t\"),\n",
    "        (\" 're\", \"'re\")\n",
    "    ]\n",
    "    \n",
    "    for from_, to in replacements:\n",
    "        sentence = sentence.replace(from_, to)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def doc_from_tree(tree):\n",
    "    return process_text(text_from_tree(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjectives(tree):\n",
    "#     doc = doc_from_tree(tree)\n",
    "    \n",
    "#     return Counter(token.lemma_ for token in doc if token.pos_ == 'ADJ')\n",
    "\n",
    "# adjectives_softmax_experiment = experiment(adjectives, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tokens = ['<S>'] + tree.leaves() + ['</S>']\n",
    "    bigrams = ngrams(tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.896     0.960     0.927      3310\n",
      "     neutral      0.979     0.744     0.846      1624\n",
      "    positive      0.922     0.961     0.941      3610\n",
      "\n",
      "   micro avg      0.919     0.919     0.919      8544\n",
      "   macro avg      0.932     0.889     0.905      8544\n",
      "weighted avg      0.923     0.919     0.918      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.617     0.685     0.649       428\n",
      "     neutral      0.289     0.105     0.154       229\n",
      "    positive      0.615     0.752     0.677       444\n",
      "\n",
      "   micro avg      0.591     0.591     0.591      1101\n",
      "   macro avg      0.507     0.514     0.493      1101\n",
      "weighted avg      0.548     0.591     0.557      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def non_stopword_unigrams(tree):\n",
    "    doc = doc_from_tree(tree)\n",
    "    return Counter(\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_space and not token.is_punct\n",
    "    )\n",
    "\n",
    "non_stopwords_softmax_experiment = experiment(non_stopword_unigrams, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.998     1.000     0.999      3310\n",
      "     neutral      0.999     0.993     0.996      1624\n",
      "    positive      0.998     0.999     0.999      3610\n",
      "\n",
      "   micro avg      0.998     0.998     0.998      8544\n",
      "   macro avg      0.998     0.997     0.998      8544\n",
      "weighted avg      0.998     0.998     0.998      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.598     0.621     0.609       428\n",
      "     neutral      0.328     0.092     0.143       229\n",
      "    positive      0.590     0.786     0.674       444\n",
      "\n",
      "   micro avg      0.578     0.578     0.578      1101\n",
      "   macro avg      0.505     0.500     0.475      1101\n",
      "weighted avg      0.538     0.578     0.538      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def non_stopword_bigrams(tree):\n",
    "    doc = doc_from_tree(tree)\n",
    "    lemmas = ['<S>'] + [token.lemma_ for token in doc] + ['</S>']\n",
    "    lemma_bigrams = ngrams(lemmas, 2)\n",
    "    return Counter(lemma_bigrams)\n",
    "\n",
    "non_stopword_bigrams_softmax_experiment = experiment(non_stopword_bigrams, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.869     0.876     0.872      3310\n",
      "     neutral      0.989     0.565     0.719      1624\n",
      "    positive      0.797     0.945     0.864      3610\n",
      "\n",
      "   micro avg      0.846     0.846     0.846      8544\n",
      "   macro avg      0.885     0.795     0.819      8544\n",
      "weighted avg      0.861     0.846     0.840      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.517     0.472     0.493       428\n",
      "     neutral      0.107     0.013     0.023       229\n",
      "    positive      0.466     0.716     0.565       444\n",
      "\n",
      "   micro avg      0.475     0.475     0.475      1101\n",
      "   macro avg      0.363     0.400     0.360      1101\n",
      "weighted avg      0.411     0.475     0.424      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "_matcher = Matcher(_nlp.vocab)\n",
    "_matcher.add('Phrase', None, [{\"POS\": \"ADJ\", \"OP\": \"*\"}, {\"POS\": \"NOUN\", \"OP\": \"+\"}])\n",
    "\n",
    "def noun_phrases(tree):\n",
    "    doc = doc_from_tree(tree)\n",
    "    matches = _matcher(doc)\n",
    "    seen = set()\n",
    "    counter = Counter()\n",
    "    \n",
    "    spans = [doc[start:end] for (_, start, end) in matches]\n",
    "    spans.sort(key=len, reverse=True)\n",
    "    \n",
    "    for span in sorted(spans, key=len, reverse=True):\n",
    "        lemma_text = span.lemma_\n",
    "        \n",
    "        if lemma_text not in seen:\n",
    "            counter[lemma_text] += 1\n",
    "        \n",
    "        for token in span:\n",
    "            seen.add(token.lemma_)\n",
    "\n",
    "    return counter\n",
    "\n",
    "noun_phrases_softmax_experiment = experiment(noun_phrases, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/colin/.pyenv/versions/3.7.4/envs/374/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 3.0, 'fit_intercept': False, 'penalty': 'l2'}\n",
      "Best score: 0.471\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.999     1.000     1.000      3310\n",
      "     neutral      1.000     0.999     0.999      1624\n",
      "    positive      1.000     1.000     1.000      3610\n",
      "\n",
      "   micro avg      1.000     1.000     1.000      8544\n",
      "   macro avg      1.000     1.000     1.000      8544\n",
      "weighted avg      1.000     1.000     1.000      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.599     0.607     0.603       428\n",
      "     neutral      0.262     0.096     0.141       229\n",
      "    positive      0.581     0.764     0.660       444\n",
      "\n",
      "   micro avg      0.564     0.564     0.564      1101\n",
      "   macro avg      0.481     0.489     0.468      1101\n",
      "weighted avg      0.522     0.564     0.530      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_stopword_bigrams_softmax_experiment_grid = experiment(non_stopword_bigrams, fit_softmax_with_crossvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.647     0.778     0.707      3310\n",
      "     neutral      0.481     0.088     0.149      1624\n",
      "    positive      0.687     0.812     0.745      3610\n",
      "\n",
      "   micro avg      0.662     0.662     0.662      8544\n",
      "   macro avg      0.605     0.560     0.533      8544\n",
      "weighted avg      0.633     0.662     0.617      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.617     0.722     0.665       428\n",
      "     neutral      0.286     0.052     0.089       229\n",
      "    positive      0.622     0.782     0.693       444\n",
      "\n",
      "   micro avg      0.607     0.607     0.607      1101\n",
      "   macro avg      0.508     0.519     0.482      1101\n",
      "weighted avg      0.550     0.607     0.556      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_summed_softmax_experiment = experiment(glove_leaves_phi, fit_softmax_classifier, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.640     0.784     0.705      3310\n",
      "     neutral      0.537     0.076     0.133      1624\n",
      "    positive      0.686     0.810     0.743      3610\n",
      "\n",
      "   micro avg      0.661     0.661     0.661      8544\n",
      "   macro avg      0.621     0.557     0.527      8544\n",
      "weighted avg      0.640     0.661     0.612      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.613     0.724     0.664       428\n",
      "     neutral      0.400     0.044     0.079       229\n",
      "    positive      0.619     0.795     0.696       444\n",
      "\n",
      "   micro avg      0.611     0.611     0.611      1101\n",
      "   macro avg      0.544     0.521     0.480      1101\n",
      "weighted avg      0.571     0.611     0.555      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_averaged_softmax_experiment = experiment(\n",
    "    lambda tree: glove_leaves_phi(tree, np_func=np.mean),\n",
    "    fit_softmax_classifier,\n",
    "    vectorize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.593     0.673     0.631      3310\n",
      "     neutral      0.611     0.047     0.088      1624\n",
      "    positive      0.606     0.783     0.683      3610\n",
      "\n",
      "   micro avg      0.601     0.601     0.601      8544\n",
      "   macro avg      0.603     0.501     0.467      8544\n",
      "weighted avg      0.602     0.601     0.550      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.587     0.654     0.619       428\n",
      "     neutral      0.556     0.044     0.081       229\n",
      "    positive      0.569     0.777     0.657       444\n",
      "\n",
      "   micro avg      0.577     0.577     0.577      1101\n",
      "   macro avg      0.571     0.492     0.452      1101\n",
      "weighted avg      0.573     0.577     0.522      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _glove_averaged_constituents_phi(tree_or_leaf):\n",
    "    if isinstance(tree_or_leaf, str):\n",
    "        word = tree_or_leaf\n",
    "        vector = glove_lookup.get(word)\n",
    "        return vector\n",
    "\n",
    "    tree = tree_or_leaf\n",
    "    \n",
    "    vectors = []\n",
    "    for child in tree:\n",
    "        vector = _glove_averaged_constituents_phi(child)\n",
    "        if vector is not None:\n",
    "            vectors.append(vector)\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "def glove_averaged_constituents_phi(tree):\n",
    "    vector = _glove_averaged_constituents_phi(tree)    \n",
    "    ret = vector if vector is not None else np.zeros(glove_lookup['word'].shape)\n",
    "    assert isinstance(ret, np.ndarray)\n",
    "    return ret\n",
    "\n",
    "\n",
    "glove_constituents_averaged_softmax_experiment = experiment(\n",
    "    glove_averaged_constituents_phi,\n",
    "    fit_softmax_classifier,\n",
    "    vectorize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.953     0.987     0.970      3310\n",
      "     neutral      0.985     0.873     0.926      1624\n",
      "    positive      0.968     0.986     0.977      3610\n",
      "\n",
      "   micro avg      0.965     0.965     0.965      8544\n",
      "   macro avg      0.969     0.949     0.957      8544\n",
      "weighted avg      0.965     0.965     0.964      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.629     0.699     0.662       428\n",
      "     neutral      0.326     0.135     0.191       229\n",
      "    positive      0.633     0.757     0.689       444\n",
      "\n",
      "   micro avg      0.605     0.605     0.605      1101\n",
      "   macro avg      0.530     0.530     0.514      1101\n",
      "weighted avg      0.568     0.605     0.575      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def unigrams_negated_phi(tree):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.tree\n",
    "        The tree to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    Counter\n",
    "        A map from strings to their counts in `tree`. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \n",
    "    \"\"\"\n",
    "    token_counts = Counter()\n",
    "    \n",
    "    is_negated = False\n",
    "    for token in tree.leaves():\n",
    "        if token in ('not', \"n't\"):\n",
    "            is_negated = True\n",
    "        \n",
    "        elif token in (',;.'):\n",
    "            is_negated = False\n",
    "        else:\n",
    "            new_token = 'not_' + token if is_negated else token\n",
    "            token_counts[new_token] += 1\n",
    "            \n",
    "    return token_counts\n",
    "\n",
    "unigrams_negated_phi_softmax_experiment = experiment(unigrams_negated_phi, fit_softmax_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.999     0.605     0.754      3310\n",
      "     neutral      0.394     1.000     0.565      1624\n",
      "    positive      1.000     0.668     0.801      3610\n",
      "\n",
      "   micro avg      0.707     0.707     0.707      8544\n",
      "   macro avg      0.797     0.758     0.707      8544\n",
      "weighted avg      0.884     0.707     0.738      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.580     0.304     0.399       428\n",
      "     neutral      0.237     0.555     0.332       229\n",
      "    positive      0.599     0.462     0.522       444\n",
      "\n",
      "   micro avg      0.420     0.420     0.420      1101\n",
      "   macro avg      0.472     0.440     0.418      1101\n",
      "weighted avg      0.517     0.420     0.435      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _get_neutrality_split_data(X, y):\n",
    "    \"\"\"Segment X and y into (neutral vs non-neutral) and (pos vs neg).\"\"\"\n",
    "    neutral_indices = [i for (i, y_) in enumerate(y) if y_ == 'neutral']\n",
    "    negative_indices = [i for (i, y_) in enumerate(y) if y_ == 'negative']\n",
    "    positive_indices = [i for (i, y_) in enumerate(y) if y_ == 'positive']\n",
    "\n",
    "    num_neutral = len(neutral_indices)    \n",
    "    neg_sample = random.sample(negative_indices, num_neutral // 2)\n",
    "    pos_sample = random.sample(positive_indices, num_neutral // 2)\n",
    "    \n",
    "    non_neutral_indices = neg_sample + pos_sample\n",
    "    \n",
    "    neutral_X = X[neutral_indices, :]\n",
    "    neutral_y = [y[i] for i in neutral_indices]\n",
    "\n",
    "    non_neutral_X = X[non_neutral_indices, :]\n",
    "    non_neutral_y = ['non_neutral' for i in non_neutral_indices]\n",
    "\n",
    "    pos_X = X[positive_indices, :]\n",
    "    pos_y = [y[i] for i in positive_indices]\n",
    "    \n",
    "    neg_X = X[negative_indices, :]\n",
    "    neg_y = [y[i] for i in negative_indices]\n",
    "    \n",
    "    neutrality_X = np.concatenate((neutral_X, non_neutral_X))\n",
    "    neutrality_y = neutral_y + non_neutral_y\n",
    "\n",
    "    posneg_X = np.concatenate((pos_X, neg_X))\n",
    "    posneg_y = pos_y + neg_y\n",
    "\n",
    "    return neutrality_X, neutrality_y, posneg_X, posneg_y\n",
    "    \n",
    "    \n",
    "class TwoPartClassifier:        \n",
    "    def fit(self, X, y):\n",
    "        neutrality_X, neutrality_y, posneg_X, posneg_y = _get_neutrality_split_data(X, y)\n",
    "        self._neutral_model = fit_softmax_classifier(neutrality_X, neutrality_y)\n",
    "        self._posneg_model = fit_softmax_classifier(posneg_X, posneg_y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        neutral_classifications = self._neutral_model.predict(X)\n",
    "        \n",
    "        unique_neutral_classifications = set(neutral_classifications)\n",
    "\n",
    "        # This loops through all of the neutrality classifications. Neutrals\n",
    "        # are put in `y` while non-neutrals are classified by the posneg\n",
    "        # classifier and that result is put in `y`. Note that this could be\n",
    "        # optimized by classifying all of `X` that is non-neutral at once.\n",
    "        y = []        \n",
    "        for i, classification in enumerate(self._neutral_model.predict(X)):\n",
    "            if classification == 'neutral':\n",
    "                y.append(classification)\n",
    "            else:\n",
    "                posneg_classification = self._posneg_model.predict(X[i, :].reshape(1, -1)).item()\n",
    "                assert posneg_classification in ('positive', 'negative')\n",
    "                y.append(posneg_classification)\n",
    "        return y\n",
    "\n",
    "def fit_two_part_softmax(X, y):\n",
    "    model = TwoPartClassifier()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "unigrams_two_part_softmax_experiment = experiment(bigrams_phi, fit_two_part_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xf46699150>"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = unigrams_two_part_softmax_experiment.copy()\n",
    "t['predictions'] = t['dev_predictions']\n",
    "a = find_errors(t)\n",
    "a.groupby('gold').correct.mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-part classifier greatly improved the performance on neutral gold sentences at the expense of other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_fairseq_master\n",
      "100%|██████████| 655283069/655283069 [00:10<00:00, 61535629.42B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /home/ubuntu/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "extracting archive file /home/ubuntu/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2 to temp dir /tmp/tmplfv0wre6\n",
      "| dictionary: 50264 types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1042301B [00:00, 3436989.77B/s]\n",
      "456318B [00:00, 4857077.92B/s]\n"
     ]
    }
   ],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.763     0.883     0.819      3310\n",
      "     neutral      0.668     0.284     0.398      1624\n",
      "    positive      0.809     0.902     0.853      3610\n",
      "\n",
      "    accuracy                          0.777      8544\n",
      "   macro avg      0.747     0.690     0.690      8544\n",
      "weighted avg      0.764     0.777     0.753      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.685     0.827     0.749       428\n",
      "     neutral      0.397     0.135     0.202       229\n",
      "    positive      0.745     0.849     0.794       444\n",
      "\n",
      "    accuracy                          0.692      1101\n",
      "   macro avg      0.609     0.604     0.582      1101\n",
      "weighted avg      0.649     0.692     0.653      1101\n",
      "\n",
      "CPU times: user 7min 28s, sys: 33.2 s, total: 8min 1s\n",
      "Wall time: 8min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def bert_features(tree):\n",
    "    text = text_from_tree(tree)\n",
    "    tokens = roberta.encode(text)\n",
    "    features = roberta.extract_features(tokens)\n",
    "    \n",
    "    return features.cpu().detach().numpy().squeeze().mean(axis=0)\n",
    "\n",
    "bert_softmax_experiment = experiment(bert_features, fit_softmax_classifier, vectorize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 minutes on p2.xlarge (down from 36 on my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.762     0.892     0.822      3310\n",
      "     neutral      0.684     0.281     0.399      1624\n",
      "    positive      0.812     0.899     0.853      3610\n",
      "\n",
      "   micro avg      0.779     0.779     0.779      8544\n",
      "   macro avg      0.753     0.691     0.691      8544\n",
      "weighted avg      0.768     0.779     0.755      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.710     0.808     0.756       428\n",
      "     neutral      0.422     0.166     0.238       229\n",
      "    positive      0.729     0.860     0.789       444\n",
      "\n",
      "   micro avg      0.696     0.696     0.696      1101\n",
      "   macro avg      0.621     0.612     0.595      1101\n",
      "weighted avg      0.658     0.696     0.662      1101\n",
      "\n",
      "CPU times: user 2h 8min 58s, sys: 11min 59s, total: 2h 20min 57s\n",
      "Wall time: 35min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def bert_features(tree):\n",
    "    text = text_from_tree(tree)\n",
    "    tokens = roberta.encode(text)\n",
    "    features = roberta.extract_features(tokens)\n",
    "    \n",
    "    return features.detach().numpy().squeeze().mean(axis=0)\n",
    "\n",
    "bert_softmax_experiment = experiment(bert_features, fit_softmax_classifier, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.763     0.888     0.820      3310\n",
      "     neutral      0.679     0.286     0.403      1624\n",
      "    positive      0.806     0.894     0.848      3610\n",
      "\n",
      "   micro avg      0.776     0.776     0.776      8544\n",
      "   macro avg      0.749     0.689     0.690      8544\n",
      "weighted avg      0.765     0.776     0.753      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.716     0.794     0.753       428\n",
      "     neutral      0.353     0.157     0.218       229\n",
      "    positive      0.737     0.869     0.798       444\n",
      "\n",
      "   micro avg      0.692     0.692     0.692      1101\n",
      "   macro avg      0.602     0.607     0.589      1101\n",
      "weighted avg      0.649     0.692     0.660      1101\n",
      "\n",
      "CPU times: user 2h 12min 39s, sys: 13min 6s, total: 2h 25min 45s\n",
      "Wall time: 37min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def bert_features_v2(tree):\n",
    "    text = text_from_tree(tree)\n",
    "    tokens = roberta.encode(text)\n",
    "    features = roberta.extract_features(tokens)\n",
    "    \n",
    "    return features.detach().numpy().squeeze().mean(axis=1)\n",
    "\n",
    "bert_softmax_experiment_v2_experiment = experiment(bert_features, fit_softmax_classifier, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = bert_softmax_experiment['train_dataset']['raw_examples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_train_reader(sst_home, class_func):\n",
    "    src_filename = os.path.join(sst_home, 'train.txt')\n",
    "    class_func = sst.ternary_class_func\n",
    "    with open(src_filename, encoding='utf8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            tree = Tree.fromstring(line)\n",
    "            label = class_func(tree.label())\n",
    "            # As in the paper, if the root node doesn't fall into any\n",
    "            # of the classes for this version of the problem, then\n",
    "            # we drop the example:\n",
    "            if label:\n",
    "                for subtree in tree.subtrees():\n",
    "                    subtree.set_label(class_func(subtree.label()))\n",
    "                yield (tree, label)\n",
    "            if idx > 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### end Bert ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis of the best non-DL model so far ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_examples</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gold</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It 's a lovely film with lovely performances by Buy and Accorsi .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No one goes unindicted here , which is probably for the best .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A warm , funny , engaging film .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                     raw_examples  \\\n",
       "0                                                                               It 's a lovely film with lovely performances by Buy and Accorsi .   \n",
       "1                                                                                  No one goes unindicted here , which is probably for the best .   \n",
       "2                                          And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .   \n",
       "3                                                                                                                A warm , funny , engaging film .   \n",
       "4  Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .   \n",
       "\n",
       "  predicted      gold  correct  \n",
       "0  positive  positive     True  \n",
       "1  negative   neutral    False  \n",
       "2  positive  positive     True  \n",
       "3  positive  positive     True  \n",
       "4  positive  positive     True  "
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = unigrams_negated_phi_softmax_experiment.copy()\n",
    "t['predictions'] = t['dev_predictions']\n",
    "analysis = find_errors(t)\n",
    "analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = analysis.groupby('gold').correct.mean().plot.bar(title='Correct Rate by Gold Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7858910891089109"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[(analysis.gold != 'neutral') & (analysis.predicted != 'neutral')].correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>299</td>\n",
       "      <td>38</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>94</td>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  negative  neutral  positive\n",
       "gold                                  \n",
       "negative        299       38        91\n",
       "neutral          94       31       104\n",
       "positive         82       26       336"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab = pd.crosstab(analysis.gold, analysis.predicted)\n",
    "total = crosstab.sum().sum()\n",
    "crosstab / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_examples</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gold</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Writer\\/director Mark Romanek spotlights the underlying caste system in America .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>At all .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Open-minded kids -- kids who read , kids who dream -- will be comforted by the way it deals with big issues like death and destiny .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Although the level of the comedy declines as the movie proceeds , there 's no denying the fun of watching De Niro and Crystal having fun .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Ah yes , and then there 's the music ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Like the Chelsea 's denizens ... Burdette 's collage-form scenario tends to over-romanticize the spiritual desolation of the struggling artiste .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>It 's a coming-of-age story we 've all seen bits of in other films -- but it 's rarely been told with such affecting grace and cultural specificity .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Van Wilder does n't bring anything new to the proverbial table , but it does possess a coherence absent in recent crass-a-thons like Tomcats , Freddy Got Fingered , and Slackers .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>Not nearly long enough .</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Christina Ricci comedy about sympathy , hypocrisy and love is a misfire .</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                             raw_examples  \\\n",
       "322                                                                                                     Writer\\/director Mark Romanek spotlights the underlying caste system in America .   \n",
       "401                                                                                                                                                                              At all .   \n",
       "354                                                  Open-minded kids -- kids who read , kids who dream -- will be comforted by the way it deals with big issues like death and destiny .   \n",
       "336                                            Although the level of the comedy declines as the movie proceeds , there 's no denying the fun of watching De Niro and Crystal having fun .   \n",
       "236                                                                                                                                              Ah yes , and then there 's the music ...   \n",
       "1007                                    Like the Chelsea 's denizens ... Burdette 's collage-form scenario tends to over-romanticize the spiritual desolation of the struggling artiste .   \n",
       "60                                  It 's a coming-of-age story we 've all seen bits of in other films -- but it 's rarely been told with such affecting grace and cultural specificity .   \n",
       "578   Van Wilder does n't bring anything new to the proverbial table , but it does possess a coherence absent in recent crass-a-thons like Tomcats , Freddy Got Fingered , and Slackers .   \n",
       "1038                                                                                                                                                             Not nearly long enough .   \n",
       "558                                                                                                             Christina Ricci comedy about sympathy , hypocrisy and love is a misfire .   \n",
       "\n",
       "     predicted     gold  correct  \n",
       "322   positive  neutral    False  \n",
       "401   negative  neutral    False  \n",
       "354   positive  neutral    False  \n",
       "336   positive  neutral    False  \n",
       "236   negative  neutral    False  \n",
       "1007  negative  neutral    False  \n",
       "60    positive  neutral    False  \n",
       "578   negative  neutral    False  \n",
       "1038  negative  neutral    False  \n",
       "558   positive  neutral    False  "
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[(~analysis.correct) & (analysis.gold=='neutral')].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_examples</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gold</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>It offers little beyond the momentary joys of pretty and weightless intellectual entertainment .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>The longer the movie goes , the worse it gets , but it 's actually pretty good in the first few minutes .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>It 's everything you do n't go to the movies for .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>A sequence of ridiculous shoot - 'em - up scenes .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>The film is based on truth and yet there is something about it that feels incomplete , as if the real story starts just around the corner .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Even on those rare occasions when the narrator stops yammering , Miller 's hand often feels unsure .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Expect the same-old , lame-old slasher nonsense , just with different scenery .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>The best that can be said about the work here of Scottish director Ritchie ... is that he obviously does n't have his heart in it .</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>A broad , melodramatic estrogen opera that 's pretty toxic in its own right .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>If the movie succeeds in instilling a wary sense of ` there but for the grace of God , ' it is far too self-conscious to draw you deeply into its world .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   raw_examples  \\\n",
       "1056                                                           It offers little beyond the momentary joys of pretty and weightless intellectual entertainment .   \n",
       "677                                                   The longer the movie goes , the worse it gets , but it 's actually pretty good in the first few minutes .   \n",
       "941                                                                                                          It 's everything you do n't go to the movies for .   \n",
       "1057                                                                                                         A sequence of ridiculous shoot - 'em - up scenes .   \n",
       "600                 The film is based on truth and yet there is something about it that feels incomplete , as if the real story starts just around the corner .   \n",
       "722                                                        Even on those rare occasions when the narrator stops yammering , Miller 's hand often feels unsure .   \n",
       "634                                                                             Expect the same-old , lame-old slasher nonsense , just with different scenery .   \n",
       "564                         The best that can be said about the work here of Scottish director Ritchie ... is that he obviously does n't have his heart in it .   \n",
       "711                                                                               A broad , melodramatic estrogen opera that 's pretty toxic in its own right .   \n",
       "630   If the movie succeeds in instilling a wary sense of ` there but for the grace of God , ' it is far too self-conscious to draw you deeply into its world .   \n",
       "\n",
       "     predicted      gold  correct  \n",
       "1056  positive  negative    False  \n",
       "677    neutral  negative    False  \n",
       "941    neutral  negative    False  \n",
       "1057   neutral  negative    False  \n",
       "600    neutral  negative    False  \n",
       "722   positive  negative    False  \n",
       "634   positive  negative    False  \n",
       "564   positive  negative    False  \n",
       "711    neutral  negative    False  \n",
       "630    neutral  negative    False  "
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[(~analysis.correct) & (analysis.gold=='negative')].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_examples</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gold</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>While there 's something intrinsically funny about Sir Anthony Hopkins saying ` Get in the car , bitch , ' this Jerry Bruckheimer production has little else to offer</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>What better message than ` love thyself ' could young women of any size receive ?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Whether writer-director Anne Fontaine 's film is a ghost story , an account of a nervous breakdown , a trip down memory lane , all three or none of the above , it is as seductive as it is haunting .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>On the heels of The Ring comes a similarly morose and humorless horror movie that , although flawed , is to be commended for its straight-ahead approach to creepiness .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Another one of those estrogen overdose movies like `` Divine Secrets of the Ya Ya Sisterhood , '' except that the writing , acting and character development are a lot better .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Charles ' entertaining film chronicles Seinfeld 's return to stand-up comedy after the wrap of his legendary sitcom , alongside wannabe comic Adams ' attempts to get his shot at the big time .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>It is amusing , and that 's all it needs to be .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Overall very good for what it 's trying to do .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Against all odds in heaven and hell , it creeped me out just fine .</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Jaglom ... put -LRB- s -RRB- the audience in the privileged position of eavesdropping on his characters</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               raw_examples  \\\n",
       "975                                   While there 's something intrinsically funny about Sir Anthony Hopkins saying ` Get in the car , bitch , ' this Jerry Bruckheimer production has little else to offer   \n",
       "107                                                                                                                       What better message than ` love thyself ' could young women of any size receive ?   \n",
       "473  Whether writer-director Anne Fontaine 's film is a ghost story , an account of a nervous breakdown , a trip down memory lane , all three or none of the above , it is as seductive as it is haunting .   \n",
       "434                                On the heels of The Ring comes a similarly morose and humorless horror movie that , although flawed , is to be commended for its straight-ahead approach to creepiness .   \n",
       "478                         Another one of those estrogen overdose movies like `` Divine Secrets of the Ya Ya Sisterhood , '' except that the writing , acting and character development are a lot better .   \n",
       "346        Charles ' entertaining film chronicles Seinfeld 's return to stand-up comedy after the wrap of his legendary sitcom , alongside wannabe comic Adams ' attempts to get his shot at the big time .   \n",
       "272                                                                                                                                                        It is amusing , and that 's all it needs to be .   \n",
       "284                                                                                                                                                         Overall very good for what it 's trying to do .   \n",
       "68                                                                                                                                      Against all odds in heaven and hell , it creeped me out just fine .   \n",
       "91                                                                                                  Jaglom ... put -LRB- s -RRB- the audience in the privileged position of eavesdropping on his characters   \n",
       "\n",
       "    predicted      gold  correct  \n",
       "975  negative  positive    False  \n",
       "107   neutral  positive    False  \n",
       "473  negative  positive    False  \n",
       "434  negative  positive    False  \n",
       "478  negative  positive    False  \n",
       "346  negative  positive    False  \n",
       "272  negative  positive    False  \n",
       "284   neutral  positive    False  \n",
       "68   negative  positive    False  \n",
       "91   negative  positive    False  "
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[(~analysis.correct) & (analysis.gold=='positive')].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off [1 point]\n",
    "\n",
    "As we said above, the bake-off evaluation data is the official SST test-set release. For this bake-off, you'll evaluate your original system from the above homework problem on the test set, using the ternary class problem. Rules:\n",
    "\n",
    "1. Only one evaluation is permitted.\n",
    "1. No additional system tuning is permitted once the bake-off has started.\n",
    "1. As noted above, __you cannot make any use of the subtree labels__.\n",
    "\n",
    "The cells below this one constitute your bake-off entry.\n",
    "\n",
    "Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points. Similarly, you cannot win the bake-off unless your homework is submitted on time.\n",
    "\n",
    "The announcement will include the details on where to submit your entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.735     0.812     0.772       912\n",
      "     neutral      0.349     0.152     0.211       389\n",
      "    positive      0.767     0.871     0.816       909\n",
      "\n",
      "   micro avg      0.720     0.720     0.720      2210\n",
      "   macro avg      0.617     0.612     0.600      2210\n",
      "weighted avg      0.680     0.720     0.691      2210\n",
      "\n",
      "CPU times: user 2h 6min 5s, sys: 7min 41s, total: 2h 13min 47s\n",
      "Wall time: 34min 4s\n"
     ]
    }
   ],
   "source": [
    "# Enter your bake-off assessment code in this cell. \n",
    "# Please do not remove this comment.\n",
    "\n",
    "##### YOUR CODE HERE\n",
    "%%time\n",
    "\n",
    "bert_softmax_test = sst.experiment(SST_HOME, bert_features, fit_softmax_classifier, vectorize=False, assess_reader=sst.test_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On an otherwise blank line in this cell, please enter\n",
    "# your macro-average F1 value as reported by the code above. \n",
    "# Please enter only a number between 0 and 1 inclusive.\n",
    "# Please do not remove this comment.\n",
    "\n",
    "0.600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-implementing top Models from the Class ##\n",
    "* Filter sentences to re-join contractions etc. that were split out. Not sure how much this matters.\n",
    "* Oversample to balance the dataset. I forgot the neutral set was smaller.\n",
    "\n",
    "Model\n",
    "1. [.692] Use HuggingFace Bert to fine-tune the pretrained Bert.\n",
    "2. [.651] Fine-tune Bert on SST. Run inference to generate features. Use TorchShallowNeuralClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 3610, 'neutral': 1624, 'negative': 3310})"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(bert_softmax_experiment['train_dataset']['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO ###\n",
    "* Balance the training set and see how that affects performance.\n",
    "* Extract bert features for every tree and store them in a dict or something. Write an featurizer that pulls them from the dict. Try it with the logistic regression classifier\n",
    "* Use the features in a relatively shallow NN. 1024 input features\n",
    "* Fine-tune bert\n",
    "  * Read https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampled(fit_func):\n",
    "    @functools.wraps(fit_func)\n",
    "    def oversampled_fit_func(X, y):\n",
    "        oversampler = RandomOverSampler()\n",
    "        X_new, y_new = oversampler.fit_sample(X, y)\n",
    "        return fit_func(X_new, y_new)\n",
    "\n",
    "    return oversampled_fit_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cache = diskcache.Cache('__bert_cache__')\n",
    "\n",
    "def _bert_features(text):\n",
    "    tokens = roberta.encode(text)\n",
    "    features = roberta.extract_features(tokens)\n",
    "    \n",
    "    return features.cpu().detach().numpy().squeeze()\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def bert_features(text):\n",
    "    from_cache = bert_cache.get(text)\n",
    "    if from_cache is not None:\n",
    "        return from_cache\n",
    "    \n",
    "    features = _bert_features(text)\n",
    "    bert_cache[text] = features\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_features_mean(tree):\n",
    "    text = text_from_tree(tree)\n",
    "    features = bert_features(text)\n",
    "    return features.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H2>Train</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.818     0.799     0.808      3310\n",
      "     neutral      0.522     0.602     0.559      1624\n",
      "    positive      0.871     0.829     0.849      3610\n",
      "\n",
      "    accuracy                          0.774      8544\n",
      "   macro avg      0.737     0.743     0.739      8544\n",
      "weighted avg      0.784     0.774     0.778      8544\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<H2>Dev</H2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.736     0.715     0.725       428\n",
      "     neutral      0.347     0.367     0.357       229\n",
      "    positive      0.783     0.782     0.782       444\n",
      "\n",
      "    accuracy                          0.669      1101\n",
      "   macro avg      0.622     0.621     0.621      1101\n",
      "weighted avg      0.674     0.669     0.672      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_softmax_oversampled_exp = experiment(bert_features_mean, oversampled(fit_softmax_classifier), vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden_1, n_hidden_2, n_output_classes):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_inputs, n_hidden_1)\n",
    "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.fc3 = nn.Linear(n_hidden_2, n_output_classes)\n",
    "        self.g = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.g(self.fc1(x))\n",
    "        x = self.g(self.fc2(x))\n",
    "        x = self.g(self.fc3(x))\n",
    "        x = self.softmax(x.reshape(-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "def make_data_loader(X, y, batch_size=32, shuffle=True):\n",
    "    dataset = MyDataset(X, y)\n",
    "    return data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, epochs=5):\n",
    "    assert torch.cuda.is_available()\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    model = Net(1024, 20, 10, 3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        for (x_i, y_i) in tqdm(data_loader):\n",
    "            preds = model(x_i)\n",
    "            print('preds:', preds.shape)\n",
    "            print('y_i:', y_i.shape)\n",
    "            loss = criterion(preds, y_i)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def fit_nn(X, y):\n",
    "    y_mapper = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    y_scalar = np.array([y_mapper[y_] for y_ in y])\n",
    "    data_loader = make_data_loader(X, y_scalar)    \n",
    "    return train(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_softmax_oversampled_exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a9f1ea9ea4e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_softmax_oversampled_exp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_softmax_oversampled_exp' is not defined"
     ]
    }
   ],
   "source": [
    "tmp = bert_softmax_oversampled_exp['train_dataset']\n",
    "X = tmp['X']\n",
    "y = tmp['y']\n",
    "\n",
    "model = fit_nn(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
